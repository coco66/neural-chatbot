{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle\n",
    "from collections import OrderedDict\n",
    "import collections\n",
    "from nltk.metrics import *\n",
    "import operator\n",
    "import os\n",
    "from PST_engine import PSTInfer, PST\n",
    "from scipy.stats import rv_discrete\n",
    "\"\"\"\n",
    "    we assume this ipython notebook resides in the following git-repo directory structure:\n",
    "    ir2\n",
    "    |---src\n",
    "        |----preprocessing\n",
    "                ipython notebook\n",
    "        |----data\n",
    "             | -- bg_session.ctx\n",
    "                  tr_session.ctx\n",
    "                  ...\n",
    "        |----baseline (directory of Allesandro programs)\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "# raw session files, query words, tab separated queries, space separated words, one line=one session\n",
    "bg_session_filename = os.path.join(DATA_PATH, 'bg_session.ctx')\n",
    "val_session_filename = os.path.join(DATA_PATH,'val_session.ctx')\n",
    "test_session_filename = os.path.join(DATA_PATH,'test_session.ctx')\n",
    "tr_session_filename = os.path.join(DATA_PATH,'tr_session.ctx')\n",
    "# query frequency dict of the background data\n",
    "bg_query_freq_file = os.path.join(DATA_PATH, 'bg_query_freq.pkl')\n",
    "bg_query_dict_file = os.path.join(DATA_PATH, 'bg_query_dict.pkl')\n",
    "# ADJ model filename of background data (generated with Allesandro programs)\n",
    "bg_ADJ_model_filename = os.path.join(DATA_PATH, 'bg_session.ctx_ADJ.mdl')\n",
    "# VMM model filename of background data (generated with Allesandro programs)\n",
    "VMM_model_file = os.path.join(DATA_PATH, 'bg_session.ctx_VMM.mdl')\n",
    "# after loading it once, we can save it to pickle and load pickle file next time...which is quicker\n",
    "VMM_model_pickle = os.path.join(DATA_PATH, 'bg_pstreeVMM.pkl')\n",
    "# candidate filename, used to store the dict that holds the sessions & candidate queries for test/val/train\n",
    "tr_sess_candid_f = os.path.join(DATA_PATH, 'tr_suggest.pkl')\n",
    "val_sess_candid_f = os.path.join(DATA_PATH, 'val_suggest.pkl')\n",
    "test_sess_candid_f = os.path.join(DATA_PATH, 'test_suggest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ADJ model from file ../data/bg_session.ctx_ADJ.mdl\n",
      "Successfully loaded ADJ model dicts\n",
      "\t 5455244 entries in tuple dict\n",
      "\t 3949947 entries in query_to_id dict\n",
      "Successfully made background frequency dictionary\n",
      "Successfully saved dict to ../data/bg_query_freq.pkl\n",
      "Successfully saved dict to ../data/bg_query_dict.pkl\n",
      "Start making search dict...\n",
      "Successfully made search dict\n",
      " ---------->>> READY let's start <<<-----------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Func to print the suggested query id's as strings using the id_to_query map\n",
    "\"\"\"\n",
    "def print_suggestion(suggestions):\n",
    "    for suggest in suggestions:\n",
    "        print id_to_query[suggest[0]]\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "    Save a dictionary to file\n",
    "\"\"\"\n",
    "def save_pickle_dict(a_dict, output_file):\n",
    "    f = open(output_file, 'wb')\n",
    "    cPickle.dump(a_dict, f)\n",
    "    print(\"Successfully saved dict to %s\" % output_file)\n",
    "    f.close()\n",
    "\n",
    "\"\"\"\n",
    "    make a inverted version of the query to id dict\n",
    "\"\"\" \n",
    "def make_id_to_query_dict(q_to_id_dict):\n",
    "    return {v: k for k, v in q_to_id_dict.iteritems()}\n",
    "\n",
    "\"\"\"\n",
    "Make a query frequency dictionary of the background data set\n",
    "we need this dict for one of the features: \n",
    "    -- the frequency of an anchor query in the background data set\n",
    "Input: session file with string queries\n",
    "Output: dict with the query frequencies \n",
    "\"\"\"\n",
    "def make_query_frequencies(session_file):\n",
    "    global query_dict\n",
    "    \n",
    "    query_freq = {}\n",
    "    total_freq = 0\n",
    "    for num, session in enumerate(session_file):\n",
    "        session = session.strip().split('\\t')\n",
    "        for query in session:\n",
    "            query_freq[query] = query_freq.get(query, 0.) + 1.\n",
    "            total_freq += 1\n",
    "    \n",
    "    # Determine the 100 most frequent queries. These will be used later for the\n",
    "    # perturbation of a session context (exp 4.5)\n",
    "    query_noisy = sorted(query_freq.items(), key=operator.itemgetter(1), reverse=True)[:100]\n",
    "    # convert list of tuples [('google', 1908839), ('com', 982398)...] into list of query indexes\n",
    "    # we will later sample from the query indices\n",
    "    noisy_query_ids = np.array([query_dict[x[0]] for x in query_noisy])\n",
    "    noisy_query_counts = np.array([x[1] for x in query_noisy])\n",
    "    noisy_probs = noisy_query_counts * 1./np.sum(noisy_query_counts)\n",
    "    noisy_query_dist = rv_discrete(name='noisy_query_prob', values=(noisy_query_ids, noisy_probs))\n",
    "    \n",
    "    print(\"Successfully made background frequency dictionary\")\n",
    "    return query_freq, noisy_query_dist\n",
    "\n",
    "\"\"\"\n",
    "    load the 2 dicts from the ADJ model that we generated with Allesandro programs\n",
    "    we need these dicts to generate the candidate queries for a test/train/val files\n",
    "\"\"\"\n",
    "def load_ADJ_model_dicts(filename):\n",
    "    print(\"Loading ADJ model from file %s\" % filename)\n",
    "    input_handle = open(filename, 'r')\n",
    "    tuple_dict = cPickle.load(input_handle)\n",
    "    query_to_id = cPickle.load(input_handle)\n",
    "    print(\"Successfully loaded ADJ model dicts\")\n",
    "    print(\"\\t %d entries in tuple dict\" % len(tuple_dict))\n",
    "    print(\"\\t %d entries in query_to_id dict\" % len(query_to_id))\n",
    "    \n",
    "    return tuple_dict, query_to_id\n",
    "\n",
    "\"\"\"\n",
    "make a new dict with key anchor query, as value we have a new dict with keys previous query and \n",
    "their value count \n",
    "\n",
    "dict[anchor_query] = { previous_query: count_value}\n",
    "\n",
    "\"\"\"\n",
    "def make_search_dict(tuple_dict, gen_v2=False):\n",
    "    search_dict = collections.defaultdict(dict)\n",
    "    # use the keys (tuples with two query id's) of the tuple dict to make a new dict \n",
    "    tuple_pairs = tuple_dict.keys()\n",
    "    \n",
    "    print(\"Start making search dict...\")\n",
    "    for _tuple in tuple_pairs:\n",
    "        search_dict[_tuple[1]][_tuple[0]] = tuple_dict[_tuple] \n",
    "    \n",
    "    # search dict for Allesandro way of generating candidates\n",
    "    \"\"\"\n",
    "        JUST FOR TEST PURPOSES\n",
    "        GENERATING THE SEARCH_DICt thAT ALLESANDRO USES IN PSINFER class\n",
    "    \"\"\"\n",
    "    search_dict_v2 = collections.defaultdict(dict)\n",
    "    if gen_v2:\n",
    "        for key, freq in tuple_dict.items():\n",
    "            search_dict_v2[key[:-1]][key[-1]] = freq\n",
    "            \n",
    "    print(\"Successfully made search dict\")\n",
    "    del tuple_pairs\n",
    "    \n",
    "    return search_dict, search_dict_v2\n",
    "\n",
    "ADJ_tuple_dict, query_dict = load_ADJ_model_dicts(bg_ADJ_model_filename)\n",
    "# returns background query frequency dict\n",
    "# returns background noisy query distribution, contains 100 noisy query ID's you can sample from\n",
    "# e.g bg_noisy_query_dist.rvs(size=10) samples 10 query ID's from the dist\n",
    "bg_query_freq, bg_noisy_query_dist = make_query_frequencies(open(bg_session_filename, 'r'))\n",
    "save_pickle_dict(bg_query_freq, bg_query_freq_file)\n",
    "save_pickle_dict(query_dict, bg_query_dict_file)\n",
    "\n",
    "# finally make queryID to query-words dict\n",
    "id_to_query = make_id_to_query_dict(query_dict)\n",
    "search_dict, search_dict_v2 = make_search_dict(ADJ_tuple_dict)\n",
    "print(\" ---------->>> READY let's start <<<-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    THIS IS ONLY FOR TEST PURPOSES...TO DEBUG THE GENERATION OF THE SUGGESTIONS\n",
    "    THESE METHODS COME FROM PROGRAMS OF ALLESANDRO\n",
    "    PART OF THE PSINFER class\n",
    "\"\"\"\n",
    "def _find(suffix, exact_match=False):\n",
    "        global query_dict\n",
    "        global search_dict_v2\n",
    "        \n",
    "        _suffix = [query_dict.get(x, -1) for x in suffix]\n",
    "       \n",
    "        # Back off to shorter suffixes,\n",
    "        for i in range(len(_suffix)):\n",
    "            key = tuple(_suffix[i:])\n",
    "            # print(\"Search keys: \", id_to_query[key[0]])\n",
    "            if key in search_dict_v2:\n",
    "                \n",
    "                return {'last_node': key, \\\n",
    "                        'is_found': i==0 and len(_suffix)==len(suffix), \\\n",
    "                        'empty': False, \\\n",
    "                        'probs': search_dict_v2[key]}\n",
    "        # and if nothing is found\n",
    "        \n",
    "        return {'last_node': (0,), \\\n",
    "                'is_found': False, \\\n",
    "                'empty': True, \\\n",
    "                'probs' : {}}\n",
    "    \n",
    "def suggest(suffix, N=100, exact_match=False):\n",
    "        global id_to_query\n",
    "        \n",
    "        result = _find(suffix)\n",
    "\n",
    "        node = result['last_node']\n",
    "        probs = result['probs']\n",
    "\n",
    "        data = {'last_node_id' : node[0],\n",
    "                'last_node_query': id_to_query[node[0]],\n",
    "                'found' :   result['is_found'],\n",
    "                'suggestions' : [],\n",
    "                'scores' : []}\n",
    "        if node[0] == 0 or (exact_match and not data['found']):\n",
    "            return data\n",
    "        # Get top N\n",
    "        id_sugg_probs = sorted(probs.items(), key=operator.itemgetter(1), reverse=True)[:N]\n",
    "        string_sugg_probs = [(id_to_query[sugg_id], sugg_score) for sugg_id, sugg_score in id_sugg_probs]\n",
    "        sugg, score = map(list, zip(*string_sugg_probs))\n",
    "        data['suggestions'] = sugg\n",
    "        data['scores'] = score\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    THIS IS ONLY FOR TEST PURPOSES...TO DEBUG THE GENERATION OF THE SUGGESTIONS\n",
    "\"\"\"\n",
    "with open(tr_session_filename, 'r') as tr:\n",
    "    s = 0\n",
    "    for session in tr:\n",
    "        \n",
    "        suffix = session.strip().split('\\t')\n",
    "        target_query = suffix[-1]\n",
    "        anchor_query = suffix[-2]\n",
    "        suggestions = suggest(suffix[:-1], N=20)\n",
    "        if len(suggestions['scores']) > 20:\n",
    "            print(\"anchor_query \", anchor_query)\n",
    "            print(\"target_query \", target_query)\n",
    "            print(suggestions['suggestions'])\n",
    "        if s > 5000:\n",
    "            break\n",
    "        s += 1\n",
    "        \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shorten_query(query):\n",
    "    global query_dict\n",
    "    splitted_query = query.split()\n",
    "    for i in range(0,len(splitted_query)):\n",
    "        shorted_query = splitted_query[:i] + splitted_query[i+1 :]\n",
    "        shorted_query = ' '.join(shorted_query)\n",
    "        if shorted_query in query_dict:\n",
    "            return shorted_query\n",
    "   \n",
    "    if len(splitted_query) >= 1:\n",
    "        shorted_query = splitted_query[:i] + splitted_query[i+1 :]\n",
    "        shorted_query = ' '.join(shorted_query[:-1])\n",
    "        return shorten_query(shorted_query)\n",
    "    elif len(splitted_query) == 1:\n",
    "        if splitted_query[0] in query_dict:\n",
    "            return splitted_query[0]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\"\"\"\n",
    "Function that makes suggestions for a session\n",
    "\n",
    "Input: session file, *.ctx\n",
    "Output: dict with key:session_idx value: (target_query,anchor_query, session, suggestions)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def print_suggestions(session, anchor_query, candidates):\n",
    "    global id_to_query\n",
    "    \n",
    "    print(\"session \", session)\n",
    "    print(\"anchor_query \", anchor_query)\n",
    "    for query_1, query_2 in candidates:\n",
    "        print(\"query 1 \", id_to_query[query_1])\n",
    "        \n",
    "\n",
    "def make_suggestions(session_file, min_sess_length=1, max_sess_length=50, num_suggestions=20, \n",
    "                     early_stop=False, long_tail_queries=False):\n",
    "    global query_dict\n",
    "    global search_dict\n",
    "    # make a dict to save all the results\n",
    "    suggestion_dict = {}\n",
    "    c = 1\n",
    "    num_sessions = 0\n",
    "    # loop over every session in the *.ctx file\n",
    "    for idx, line in enumerate(session_file):\n",
    "        # queries are tab-separated \n",
    "        session = line.strip().split('\\t')\n",
    "        \n",
    "        # we also have to limit the session length because we can't generate a HRED log-likehood score\n",
    "        # for sessions that are too long (memory problems)\n",
    "        if len(session) >= min_sess_length+1 and len(session) <= max_sess_length:\n",
    "            target_query = session[-1] # target query is the last query Qm\n",
    "            anchor_query = session[-2] # Anchor query is the query Qm-1\n",
    "            context = session[:-1] # Qm-1 till Q1 are the context queries\n",
    "            orig_anchor_query = \"\"\n",
    "            \n",
    "            if long_tail_queries:\n",
    "                # when doing long-tail-prediction we only want queries that are not in the bg-set\n",
    "                if anchor_query not in query_dict:\n",
    "                    # make a shorter version of the query that is in the bg-set\n",
    "                    orig_anchor_query = anchor_query\n",
    "                    anchor_query = shorten_query(anchor_query)\n",
    "                    if anchor_query is None: # when it is not possible to make a smaller version\n",
    "                        continue\n",
    "                else:\n",
    "                    # if the query is in the query dict, we do not want to use this query\n",
    "                    continue\n",
    "            \n",
    "            if anchor_query in query_dict:\n",
    "                anchor_q_key =  query_dict[anchor_query] # the key of the query in the bg-set \n",
    "                # check if target query and anchor query are in the background set\n",
    "                # if key in search_dict and target_query in query_dict:\n",
    "                if anchor_query in query_dict and target_query in query_dict:\n",
    "                    \"\"\"\n",
    "                    We could use the search dict to find all the queries that follow the anchor query \n",
    "                    in the bg set, we use this queries as suggestions\n",
    "                    \"\"\"\n",
    "                    suggestions = search_dict[anchor_q_key]\n",
    "                    if len(suggestions) > num_suggestions: # we need at least 20 suggestions \n",
    "                        # print(\"suggestions \", suggestions)\n",
    "                        target_key = query_dict[target_query] # find the key of the target query\n",
    "                        list_suggestions = [(sugg_key, suggestions[sugg_key] ) \\\n",
    "                                            for sugg_key in suggestions.keys()]\n",
    "                        # sort list of tuples by second tuple entry which is the frequency count\n",
    "                        # also reverse order so it is in descending order\n",
    "                        sorted_suggestions = sorted(list_suggestions, key=lambda x: x[1])[::-1]\n",
    "                        #take only the top 20 suggestions based on counts \n",
    "                        \n",
    "                        suggestions = sorted_suggestions[0:num_suggestions]\n",
    "                        \n",
    "                        # final check, is the target query really in the set of suggestions? \n",
    "                        if target_key in (x[0] for x in suggestions): \n",
    "                            # we have a valid session, now we list all the suggestions and sort them\n",
    "                            # save this in the dict key(idx):(target_query,anchor_query, session, suggestions)\n",
    "                            suggestion_dict[idx] = (target_query, anchor_query, session, suggestions)\n",
    "                            # print_suggestions(session, anchor_query, suggestions)\n",
    "                            \n",
    "                            if early_stop:\n",
    "                                print(\"target_query \", target_query)\n",
    "                                print(\"original anchor query \", orig_anchor_query)\n",
    "                                print(\"anchor_query \", anchor_query)\n",
    "                                print(\"Sorted suggestions: \", suggestions)\n",
    "                            num_sessions += 1\n",
    "        if num_sessions > 3 and early_stop:\n",
    "            print(\"Break\")\n",
    "            break\n",
    "            \n",
    "    return suggestion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_suggestions(p_type=\"tr\", min_sess_length=1, max_sess_length=50, \n",
    "                         num_suggestions=20, load_existing=False, \n",
    "                         early_stop=False, long_tail_queries=False):\n",
    "    \"\"\"\n",
    "        find for a specific session file (train/test/val) all the corresponding\n",
    "        suggestions and store result in a dict for later processing\n",
    "        This procedures differs between experiments 4.4, 4.5, 4.6 in the paper\n",
    "    \"\"\"\n",
    "    global test_session_filename, tr_session_filename, val_session_filename\n",
    "    global tr_sess_candid_f, test_sess_candid_f, val_sess_candid_f\n",
    "    \n",
    "    if p_type == 'tr':\n",
    "        # training\n",
    "        session_file = tr_session_filename\n",
    "        output_file = tr_sess_candid_f\n",
    "    elif p_type == 'val':\n",
    "        # validation\n",
    "        session_file = val_session_filename\n",
    "        output_file = val_sess_candid_f\n",
    "    else:\n",
    "        # test sessions\n",
    "        session_file = test_session_filename\n",
    "        output_file = test_sess_candid_f\n",
    "        \n",
    "    if not load_existing:\n",
    "    \n",
    "        print(\"Generating suggestion queries for session file %s\" % session_file)\n",
    "        suggestion_dict = make_suggestions(open(session_file, 'r'), \n",
    "                                           min_sess_length=min_sess_length,\n",
    "                                           max_sess_length=max_sess_length,\n",
    "                                           num_suggestions=num_suggestions,\n",
    "                                           early_stop=early_stop,\n",
    "                                           long_tail_queries=long_tail_queries)\n",
    "\n",
    "        print(\"Successfully generated suggestions for %d sessions\" % len(suggestion_dict))\n",
    "        save_pickle_dict(suggestion_dict, output_file)\n",
    "    else:\n",
    "        print(\"Loading suggestion queries from file %s\" % output_file)\n",
    "        suggestion_dict = cPickle.load(open(output_file ,'rb'))\n",
    "        print(\"Successfully loaded suggestions\")\n",
    "        \n",
    "    return suggestion_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VMM model from ../data/bg_session.ctx_VMM.mdl\n",
      "Patient, this will take a while (approx 5 minutes)\n",
      "Loading inference engine\n",
      "Preparing internal structures\n",
      "Loaded inference engine\n",
      "Successfully saved dict to ../data/bg_pstreeVMM.pkl\n",
      "======== READY ===========\n"
     ]
    }
   ],
   "source": [
    "def load_VMM_model(filename, load_saved_model=False):\n",
    "    # load the VMM model made with Allesandro's Probabilistic Suffix Tree (PST)\n",
    "    # currently the context scope is limited to D=2 which means the tuple dict contains\n",
    "    # tuples with max lenght of 3 (so the memory span is look 2 queries ahead)\n",
    "    global VMM_model_pickle\n",
    "    \n",
    "    if not load_saved_model:\n",
    "        print(\"Loading VMM model from %s\" % filename)\n",
    "        print(\"Patient, this will take a while (approx 5 minutes)\")\n",
    "        pstree = PSTInfer()\n",
    "        pstree.load(filename)\n",
    "        save_pickle_dict(pstree, VMM_model_pickle)\n",
    "    else:\n",
    "        print(\"Loading VMM model from pickle %s\" % VMM_model_pickle)\n",
    "        pstree = cPickle.load(open(VMM_model_pickle, 'rb'))\n",
    "        \n",
    "    print(\"======== READY ===========\")\n",
    "    return pstree\n",
    "\n",
    "pstreeVMM = load_VMM_model(VMM_model_file, load_saved_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating suggestion queries for session file ../data/val_session.ctx\n",
      "Successfully generated suggestions for 11330 sessions\n",
      "Successfully saved dict to ../data/val_suggest.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    we use the following output files\n",
    "    (1) training\n",
    "        tr_sess_candid_f\n",
    "        \n",
    "    (2) validation\n",
    "        val_sess_candid_f\n",
    "        \n",
    "    (3) test\n",
    "        test_sess_candid_f\n",
    "        \n",
    "    if called with load_existing=True the dict will be loaded from an earlier saved pickle file\n",
    "    \n",
    "    Experiments 4.4:\n",
    "        Paper says they are getting the following number of candidate sessions (brackets our numbers):\n",
    "            Training = 18,882 (17960)\n",
    "            Test = 9,348 (7313)\n",
    "            Validation = 6,988 (11,330)\n",
    "            Note: the split of the original AOL data file is dan on query dttm.\n",
    "                  the paper does not specify the exact separation between validation and test.\n",
    "                  they only mention that they separate the last 2 weeks of May 2006 between both \n",
    "                  sets\n",
    "\"\"\"\n",
    "\n",
    "# suggest_train = generate_suggestions(p_type=\"tr\"\n",
    "# suggest_test = generate_suggestions(p_type=\"test\"\n",
    "# sugget_val = generate_suggestions(p_type=\"val\"\n",
    "suggest_val = generate_suggestions(p_type=\"val\", min_sess_length=1, \n",
    "                                       max_sess_length = 50,\n",
    "                                       load_existing=False, \n",
    "                                       early_stop=False,\n",
    "                                       long_tail_queries=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17960\n",
      "7313\n"
     ]
    }
   ],
   "source": [
    "print(len(suggest_train))\n",
    "print(len(suggest_test))\n",
    "print(len(suggest_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_letter_ngram(sentence, n=3):\n",
    "    \"\"\"\n",
    "    How many n-grams fits in this sentenec \n",
    "    \"\"\"\n",
    "    if len(sentence) < n:\n",
    "        return set(sentence)\n",
    "    local_counts = set()\n",
    "    for k in range(len(sentence.strip()) - n + 1): \n",
    "        local_counts.add(sentence[k:k+n])\n",
    "    return local_counts\n",
    "\n",
    "def matches(ng1, ng2):\n",
    "    \"\"\"\n",
    "    For both n-gram sets how many sim elements they contain\n",
    "    \"\"\"\n",
    "    return len(ng1 & ng2)\n",
    "\n",
    "def n_gram_sim(query1, query2,n=3):\n",
    "    \"\"\"\n",
    "    return n-gram similarity between two queries \n",
    "    \"\"\"\n",
    "    return matches(count_letter_ngram(query1, n), count_letter_ngram(query2, n))\n",
    "\n",
    "def make_n_gram_sim_features(context_queries,suggestion):\n",
    "    \"\"\"\n",
    "    For every suggestion make the n-gram similarity for the context queries (at most 10)\n",
    "    \"\"\"\n",
    "    n_sim = [0] * 10\n",
    "    for idx, context_query in enumerate(context_queries):\n",
    "        if idx >=10:\n",
    "            \"\"\"\n",
    "            only do this for at most 10 context queries \n",
    "            \"\"\"\n",
    "            break\n",
    "        n_sim[idx] = n_gram_sim(suggestion, context_query,n=3)\n",
    "        \n",
    "    return n_sim\n",
    "\n",
    "\n",
    "def get_VMM_score(session, suggestion, no_normalize=False, fallback=False):\n",
    "    global pstreeVMM\n",
    "    \"\"\"\n",
    "    For every suggestion determine the VMM score (variable memory Markov score)\n",
    "    \"\"\"\n",
    "    \n",
    "    _, scores = pstreeVMM.rerank(session, suggestion, no_normalize=no_normalize, fallback=fallback)\n",
    "    \n",
    "    return scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 2 output files\n",
      "../data/val_all_hred_sess.ctx\n",
      "../data/val_all_hred_cand.ctx\n",
      "-----> Ready <------\n"
     ]
    }
   ],
   "source": [
    "def prepare_files_hred_score(suggestion_dict, out_dir, suffix='tr', num_context=None, corrupt_context=False):\n",
    "    \"\"\"\n",
    "        in order to obtain the HRED scores from Allesandro's model we need to feed the score.py \n",
    "        with two input files (note raw data = the acutal words)\n",
    "        (1) sessions, tab separated queries, space separated words\n",
    "        (2) candidates belonging to that session, so on each line tab-separated the candidate queries \n",
    "        \n",
    "        the procedures generates both output files based on the input suggestion dictionary.\n",
    "        Remember, that dicionary contains per entry all necessary information:\n",
    "        \n",
    "        out_dir is just the directory where to write to\n",
    "        \n",
    "    \"\"\"\n",
    "    global pstreeVMM\n",
    "    \"\"\"\n",
    "        contains 100 noisy query ID's, you can sample with bg_noisy_query_dist.rvs(size=1)\n",
    "        we need this for experiments 4.5 \n",
    "        where we pertubate the sessions with a randomly sampled noisy query\n",
    "        we just inject/corrupt the noisy query at a random point in the session\n",
    "    \"\"\"\n",
    "    global bg_noisy_query_dist\n",
    "    global id_to_query\n",
    "    \n",
    "    assert (num_context == None or num_context <= 3)\n",
    "    if num_context == None:\n",
    "        if not corrupt_context:\n",
    "            c_suffix = \"_all\"\n",
    "        else:\n",
    "            # perturbate context with noisy query\n",
    "            c_suffix = \"_noisy\"\n",
    "    else:\n",
    "        c_suffix = \"_c\" + str(num_context)\n",
    "    session_f = os.path.join(out_dir, suffix + c_suffix + \"_hred_sess.ctx\")\n",
    "    candid_f = os.path.join(out_dir, suffix + c_suffix + \"_hred_cand.ctx\")\n",
    "    print(\"Writing 2 output files\")\n",
    "    print(session_f)\n",
    "    print(candid_f)\n",
    "    \n",
    "    with open(session_f, 'w') as sess, open(candid_f, 'w') as cand:\n",
    "        for session_key in suggestion_dict.keys():\n",
    "            # tuple \n",
    "            session_tuple = suggestion_dict[session_key]\n",
    "            target_query = session_tuple[0]\n",
    "            # all queries except the target query (full context)\n",
    "            context_queries = session_tuple[2][:-1]\n",
    "            \n",
    "            if num_context == None:\n",
    "                # complete session context without the target query\n",
    "                # check whether we're corrupting the context with a noisy query\n",
    "                if corrupt_context:\n",
    "                    noisy_query = id_to_query[int(bg_noisy_query_dist.rvs(size=1))]\n",
    "                    pos = np.random.randint(0, len(context_queries))\n",
    "                    if pos == 0:\n",
    "                        # in front\n",
    "                        context_queries = [noisy_query] + context_queries\n",
    "                    elif pos == len(context_queries):\n",
    "                        # at the end\n",
    "                        context_queries = context_queries + [noisy_query]\n",
    "                    else:\n",
    "                        # somewhere in between\n",
    "                        context_queries = context_queries[0:pos] + [noisy_query] + context_queries[pos:]\n",
    "                        \n",
    "                else:\n",
    "                    # full query context and no corruption of session context\n",
    "                    pass\n",
    "            else:\n",
    "                # only the last num_context queries as context for the HRED score generation\n",
    "                # remember CORRUPTION OF CONTEXT only applicable if num_context == None == full context\n",
    "                # experiments 4.5 paper\n",
    "                context_queries = context_queries[-num_context:]\n",
    "            \n",
    "            suggestions = session_tuple[3]\n",
    "            queries = []\n",
    "            for idx, suggestion in enumerate(suggestions):\n",
    "                suggestion_id = suggestion[0]\n",
    "                query_words = pstreeVMM.id_to_query[suggestion_id]\n",
    "                queries.append(query_words)\n",
    "\n",
    "            sess.write(\"\\t\".join(context_queries) + \"\\n\")\n",
    "            cand.write(\"\\t\".join(queries) + \"\\n\")\n",
    "        \n",
    "    print(\"-----> Ready <------\")\n",
    "    \n",
    "\"\"\"\n",
    "    make the files that we need to generate the HRED log-likelihood scores\n",
    "    \n",
    "    For experiment 4.4.2 we need to generate different query contexts for the \n",
    "    generation of the HRED score\n",
    "    1) with only Q_(m-1) i.e. only anchor query\n",
    "    2) with Q_(m-2), Q(m-1) i.e. 2 queries in context\n",
    "    3) with Q_(m-3), Q_(m-2), Q(m-1) 3 queries in context\n",
    "    \n",
    "    - For all three context-options we need to determine the HRED score\n",
    "    - produce the feature matrix\n",
    "    - score with LambdaMart\n",
    "    \n",
    "    For experiment 4.5 we inject a noisy query in to the session context.\n",
    "    So we can't use the option num_context because that restricts session context\n",
    "    the valid combination for this experiment is:  num_context=None, corrupt_context=True\n",
    "    \n",
    "    \n",
    "\"\"\"      \n",
    "# prepare_files_hred_score(suggest_train, DATA_PATH, suffix='tr', num_context=None, corrupt_context=True) \n",
    "# prepare_files_hred_score(suggest_test, DATA_PATH, suffix='test', num_context=3, corrupt_context=False) \n",
    "prepare_files_hred_score(suggest_val_long, DATA_PATH, suffix='val', num_context=None, corrupt_context=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    count number of lines in a file\n",
    "\"\"\"\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "\"\"\"\n",
    "Function that returens a feature vector for every suggestion \n",
    "\n",
    "Input: suggestion_dict\n",
    "Output: per session a matrix [17,20] with the feature vectors \n",
    "\"\"\"\n",
    "\n",
    "def make_suggestion_features(suggestion_dict, hred_ll_file, num_features=18, do_test=False):\n",
    "    global pstreeVMM\n",
    "    global bg_query_freq\n",
    "    global query_dict\n",
    "    \n",
    "    num_of_candidates = 20\n",
    "    # Number of lines in HRED file must be equal to, -1 because of header line\n",
    "    lines_in_file = file_len(hred_ll_file)  - 1\n",
    "    expected_count = len(suggestion_dict) * num_of_candidates\n",
    "    print(\"Lines match? %d = %d\" % (lines_in_file, expected_count))\n",
    "    \n",
    "    assert lines_in_file == expected_count\n",
    "    \n",
    "    c = 0\n",
    "    \"\"\"\n",
    "        matrix_out is the final numpy matrix. The layout is as follows:\n",
    "        dim0 = number of sessions which is actually equal to the size of the suggestions dict\n",
    "               because we determined for each session from the tr, test, val session file if it passes\n",
    "               the requirements, 20 suggestions\n",
    "        dim1 = col00: anchor query ID\n",
    "               col01: suggestion/candidate query ID\n",
    "               col02: length of session (including target query!)\n",
    "               col03: how many times does the candidate/suggestion follow the anchor query in the background set\n",
    "               col04: Additionally, we use the frequency of the anchor query in the background data\n",
    "               col05: levenshtein_distance\n",
    "               col06: # of characters of suggestion query + # of words suggestion query\n",
    "               col07: frequency of suggestion query in background data\n",
    "               col08: 10 n-gram similarities\n",
    "               .\n",
    "               .\n",
    "               col17: 10 n-gram similarities\n",
    "               col18: VMM score\n",
    "               col19: HRED log-likelihood score\n",
    "               col20: label, which basically is zero except for the target query ID, which is one of the \n",
    "                      suggestion queries.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_dim = num_features + 3\n",
    "    matrix_out = np.zeros((len(suggestion_dict) * 20, feature_dim))\n",
    "    session_id = 0\n",
    "    sess_less_cand = 0\n",
    "    \n",
    "    with open(hred_ll_file, 'r') as hred_ll:\n",
    "        # read header line\n",
    "        print(\"HRED-header \", hred_ll.readline() )\n",
    "        for session_key in suggestion_dict.keys():\n",
    "            # tuple \n",
    "            session_tuple = suggestion_dict[session_key]\n",
    "            target_query = session_tuple[0]\n",
    "            target_id = query_dict[target_query]\n",
    "            context_queries = session_tuple[2][:-1]\n",
    "\n",
    "            \"\"\"\n",
    "                because we are also handling situations in which the anchor query was changed (exp 4.6)\n",
    "                in that case session_tuple[1] = shortened anchor query (which exists in the bg)\n",
    "                but we want to calculate anchor query features based on the long-tail original query\n",
    "                therefore we get the last query from the context queries (which does not contain target query)\n",
    "                \n",
    "                before we did: anchor_query = session_tuple[1]\n",
    "            \"\"\"\n",
    "            anchor_query = context_queries[-1]\n",
    "            anchor_query_id = pstreeVMM.query_to_id.get(anchor_query, -1)\n",
    "            \"\"\"\n",
    "                If   anchor_query_id = -1   after this operation\n",
    "                then we're dealing with experiment 4.6, the anchor query does not exist in the background data\n",
    "                so we can't calculate frequencies\n",
    "            \"\"\"\n",
    "            # frequency of anchor query in background data, same for all 20 suggestions, so determine here\n",
    "            bg_anchor_freq = bg_query_freq.get(anchor_query, 0)\n",
    "            \n",
    "            suggestions = session_tuple[3]\n",
    "            VMM_scores = []\n",
    "            candidates = []\n",
    "            # create an empty matrix for this session, which stores the num_of_candidates rows\n",
    "            # we're doing this because at the end of the session we will sort this matrix\n",
    "            # so that the target query (the positive candidate) is the first row in the session matrix\n",
    "            session_matrix = np.zeros((num_of_candidates, feature_dim))\n",
    "            \n",
    "            if len(suggestions) == 20:\n",
    "                for idx, suggestion in enumerate(suggestions):\n",
    "\n",
    "                    suggestion_id = suggestion[0]\n",
    "                    query_string = pstreeVMM.id_to_query[suggestion_id]\n",
    "\n",
    "                    session_matrix[idx, 0] = anchor_query_id\n",
    "                    session_matrix[idx, 1] = suggestion_id\n",
    "                    # add a feature with the session length (needed in Experiment 4.4.2 for classifying\n",
    "                    # the sessions in short, medium, long). Add one because context queries misses the target query\n",
    "                    session_matrix[idx, 2] = len(context_queries) + 1\n",
    "                    \"\"\"\"\n",
    "                    For each candidate suggestion, we count how many times it follows \n",
    "                    the anchor query in the background data and add this count as a feature.\n",
    "                    This should be the ADJ-score!!!\n",
    "                    \"\"\"\n",
    "                    follow_anchor_count = suggestion[1]\n",
    "                    \"\"\"\n",
    "                        TODO: Experiment 4.6:\n",
    "                            the \"follow_anchor_count\" is still based on the shortened anchor query\n",
    "                            which is actually \n",
    "                    \"\"\" \n",
    "                    if anchor_query_id == -1:\n",
    "                        # Experiment 4.6, anchor query has no ID and suggestion never follows\n",
    "                        # the real long-tail anchor query\n",
    "                        session_matrix[idx, 3] = 0\n",
    "                    else:\n",
    "                        session_matrix[idx, 3] = follow_anchor_count\n",
    "                    \"\"\"\n",
    "                    Additionally, we use the frequency of the anchor query in the background data.\n",
    "                    \"\"\"\n",
    "                    session_matrix[idx, 4] = bg_anchor_freq\n",
    "                    \"\"\"\n",
    "                    We also add the Levenshtein distance between the anchor and the suggestion.\n",
    "                    \"\"\"\n",
    "                    levenshtein_distance = edit_distance(anchor_query, query_string)\n",
    "                    session_matrix[idx, 5] = levenshtein_distance\n",
    "                    \"\"\"\n",
    "                    The suggestion length (characters and words)\n",
    "                    \"\"\"\n",
    "                    chars_leng = len(query_string) \n",
    "                    word_leng = len(query_string.split())\n",
    "                    session_matrix[idx, 6] = chars_leng + word_leng\n",
    "                    \"\"\"\n",
    "                        Frequency of suggestion query in background data\n",
    "                    \"\"\"\n",
    "                    session_matrix[idx, 7] = bg_query_freq[query_string]\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    We add 10 features corresponding to the character n-gram similarity \n",
    "                    between the suggestion and the 10 most recent queries in the context.\n",
    "                    \"\"\"\n",
    "                    n_gram_sim =  make_n_gram_sim_features(context_queries, query_string)\n",
    "                    session_matrix[idx, 8:18] = n_gram_sim\n",
    "                    \n",
    "\n",
    "                    VMM_score = get_VMM_score(context_queries, [query_string])\n",
    "                    VMM_scores.append(VMM_score)\n",
    "                    session_matrix[idx, 18] = VMM_score\n",
    "\n",
    "                    \"\"\"\n",
    "                    HRED Score\n",
    "                    \"\"\"\n",
    "                    hred_score = float(hred_ll.readline())\n",
    "                    session_matrix[idx, 19] = hred_score\n",
    "\n",
    "                    if target_id == suggestion_id:\n",
    "                        session_matrix[idx, 20] = 1\n",
    "                    else:\n",
    "                        session_matrix[idx, 20] = 0\n",
    "                    \n",
    "                    candidates.append(query_string)\n",
    "                # ok, let's sort the session matrix first on the last column, the label (0/1) so that the target\n",
    "                # query is the first row\n",
    "                # session_matrix = session_matrix[session_matrix[:, feature_dim-1].argsort()[::-1]]\n",
    "                # let's parse the session_matrix into our final output matrix\n",
    "                start = session_id * num_of_candidates\n",
    "                end   = start + num_of_candidates\n",
    "\n",
    "                matrix_out[start:end, :] = session_matrix\n",
    "                if do_test:\n",
    "                    print(\"session \", context_queries)\n",
    "                    print(\"anchor_query \", anchor_query)\n",
    "                    # print(\"candidates \", candidates)\n",
    "                    # print(\"VMM scores \", VMM_scores)\n",
    "                    # print(matrix_out[session_id:20,feature_dim-1])\n",
    "                    # break\n",
    "                assert np.sum(matrix_out[start:end, 20] == 1) == 1, query_string + \" \" + str(target_id) + \" \" + str(anchor_query_id)\n",
    "                session_id += 1\n",
    "                if session_id % 5000 == 0:\n",
    "                    print(\"Progress, session id %d\" % session_id)\n",
    "            else:\n",
    "                sess_less_cand += 1\n",
    "                \n",
    "            if session_id > 10 and do_test:\n",
    "                break\n",
    "\n",
    "        \n",
    "    print(\"Session with less than 20 candidates %d\" % sess_less_cand)\n",
    "    return matrix_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines match? 32620 = 32620\n",
      "('HRED-header ', '0_HED_1479568981.18\\n')\n",
      "Session with less than 20 candidates 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Please note, the output files of HRED with the ll-score are called:\n",
    "    Experiments 4.4.1 (base)\n",
    "        tr_hred_score_exp4_4_1.f\n",
    "        val_hred_score_exp4_4_1.f\n",
    "        test_hred_score_exp4_4_1.f\n",
    "        \n",
    "    Experiments 4.4.2 (with different context)\n",
    "        1 query context:\n",
    "            'tr_hred_score_exp_4_4_c1.f'\n",
    "            'test_hred_score_exp_4_4_c1.f'\n",
    "            'val_hred_score_exp_4_4_c1.f'\n",
    "        2 queries in context:\n",
    "            'tr_hred_score_exp_4_4_c2.f'\n",
    "            'test_hred_score_exp_4_4_c2.f'\n",
    "            'val_hred_score_exp_4_4_c2.f'\n",
    "        3 queries in context:\n",
    "            'tr_hred_score_exp_4_4_c3.f'\n",
    "            'test_hred_score_exp_4_4_c3.f'\n",
    "            'val_hred_score_exp_4_4_c3.f'\n",
    "            \n",
    "    Experiment 4.5 (perturbate session with ONE noisy query from background data):\n",
    "        tr_hred_score_exp_4_5.f\n",
    "        test_hred_score_exp_4_5.f\n",
    "        val_hred_score_exp_4_5.f\n",
    "        \n",
    "    Experiment 4.6 (Long-tail prediction) aka anchor query does not exist in background data\n",
    "        tr_hred_score_exp_4_6.f\n",
    "        test_hred_score_exp_4_6.f\n",
    "        val_hred_score_exp_4_6.f\n",
    "\"\"\"\n",
    "\n",
    "hred_ll_file = os.path.join(DATA_PATH, 'val_hred_score_exp_4_6.f')\n",
    "output_matrix = make_suggestion_features(suggest_val_long, hred_ll_file, num_features=18, do_test=False)\n",
    "np.savez(os.path.join(DATA_PATH, \"val_longtail_suggest_matrix\"), output_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(output_matrix[100:120, 0])\n",
    "# print(output_matrix[120:160, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(output_matrix[:, 20]) == np.argmax(output_matrix[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_PATH, 'tr_c3_suggest_matrix.npz'), 'r') as m:\n",
    "    npz = np.load(m)\n",
    "    print(type(npz))\n",
    "    tr_c3 = npz['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226600, 21)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_c3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226600, 21)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3429056.77195\n",
      "3271546.39725\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(tr_c3[:, 19]))\n",
    "print(np.sum(tr_c1[:, 19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, ' ', 17960, ' ', 0.11046770601336303)\n"
     ]
    }
   ],
   "source": [
    "num_cand = 20\n",
    "correct = 0\n",
    "sessions = 0\n",
    "for idx in np.arange(tr_c3.shape[0] / num_cand):\n",
    "    start = idx * num_cand\n",
    "    end = start + num_cand\n",
    "    hred = tr_c3[start:end, 19]\n",
    "    label = tr_c3[start:end, 20]\n",
    "    correct += np.sum(np.argmin(hred) == np.argmax(label))\n",
    "    sessions += 1\n",
    "\n",
    "print(correct, \" \", sessions, \" \", float(correct)/sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1957, ' ', 17960, ' ', 0.10896436525612473)\n"
     ]
    }
   ],
   "source": [
    "num_cand = 20\n",
    "correct = 0\n",
    "sessions = 0\n",
    "for idx in np.arange(tr_c1.shape[0] / num_cand):\n",
    "    start = idx * num_cand\n",
    "    end = start + num_cand\n",
    "    hred = tr_c1[start:end, 19]\n",
    "    label = tr_c1[start:end, 20]\n",
    "    correct += np.sum(np.argmin(hred) == np.argmax(label))\n",
    "    sessions += 1\n",
    "\n",
    "print(correct, \" \", sessions, \" \", float(correct)/sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
